{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vmPRWE059oc7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acquiring / Loading data (from previous problem) **note that tensorflow is used solely for loading the dataset (tf.keras.datasets). Further, scikitlearn is used solely for splitting the data into training sets etc. the actual deep learning implementation is done using numpy and linear algebra"
      ],
      "metadata": {
        "id": "QXR23VXB92OR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "lV6qgHQr9-dq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "E9MJc26-yp0N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shapes():\n",
        "        print(f'X Train set: {np.shape(x_train)}\\nY Train set: {np.shape(y_train)}\\n\\nX Val set: {np.shape(x_val)}\\nY val set: {np.shape(y_val)}\\n\\nX Test set: {np.shape(x_test)}\\nY Test set: {np.shape(y_test)}')\n",
        "\n",
        "# Picking random 3 classes\n",
        "\n",
        "random_classes = [0,1,5]\n",
        "def sample_subset(X, y, random_classes=random_classes):\n",
        "\n",
        "    def unison_shuffled_copies(a, b):\n",
        "        '''This function is to shuffled two numpy arrays in unison'''\n",
        "        assert len(a) == len(b)\n",
        "        p = np.random.permutation(len(a))\n",
        "        return a[p], b[p]\n",
        "\n",
        "    assert len(random_classes) == 3, 'Number of random classes must be three for this situation'\n",
        "\n",
        "    class_x_tot = []\n",
        "    class_y_tot = []\n",
        "    for label in random_classes:\n",
        "        class_x_tot.append(np.take(X, np.where(y==label)[0], axis=0))\n",
        "        class_y_tot.append(np.take(y, np.where(y==label)[0], axis=0))\n",
        "    \n",
        "    X = np.concatenate((class_x_tot[0], class_x_tot[1], class_x_tot[2]))\n",
        "    y = np.concatenate((class_y_tot[0], class_y_tot[1], class_y_tot[2]))\n",
        "\n",
        "    X, y = unison_shuffled_copies(X, y)\n",
        "    return X, y\n",
        "\n",
        "#training set\n",
        "x_train, y_train = sample_subset(x_train, y_train)\n",
        "\n",
        "#testing set\n",
        "x_test, y_test = sample_subset(x_test, y_test)\n",
        "x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(x_train, y_train, test_size = .20, random_state=1)\n",
        "\n",
        "shapes()"
      ],
      "metadata": {
        "id": "dIvQ2OVQ9umy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2acf5bb9-5c49-4929-9225-a541802243d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train set: (12000, 32, 32, 3)\n",
            "Y Train set: (12000, 1)\n",
            "\n",
            "X Val set: (3000, 32, 32, 3)\n",
            "Y val set: (3000, 1)\n",
            "\n",
            "X Test set: (3000, 32, 32, 3)\n",
            "Y Test set: (3000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorization\n",
        "1. Take the mean of the color channel\n",
        "2. Divide by 255 to normalize (this should reduce it down to 32, 32 solely)\n",
        "3. Reshape array to go from 32 x 32 dimension to one dimension (32*32 = 1024) in length\n",
        "4. Pass this in to the network with input_shape = (32 * 32)"
      ],
      "metadata": {
        "id": "RiWkCUpw-2yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(arr):\n",
        "    # take mean of color channels and normalize by dividing by 255.\n",
        "    arr = np.mean(arr, axis=3) / 255.\n",
        "\n",
        "    #reshape it to go from 2 dimensions (32 x 32) to one dimension of 1024 (32*32)\n",
        "    arr = arr.reshape((len(arr), (np.shape(arr)[1] * np.shape(arr)[2])))\n",
        "\n",
        "    #return arr\n",
        "    return arr\n",
        "\n",
        "# run the function vectorize over all the x data\n",
        "print(f'---------------Shape before----------------')\n",
        "shapes()\n",
        "\n",
        "x_train = vectorize(x_train)\n",
        "x_val = vectorize(x_val)\n",
        "x_test = vectorize(x_test)\n",
        "print(f'---------------Shape after----------------')\n",
        "shapes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRaY8CRfAGS1",
        "outputId": "c3ba4fe5-9bce-4152-a095-2dcdea19027d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Shape before----------------\n",
            "X Train set: (12000, 32, 32, 3)\n",
            "Y Train set: (12000, 1)\n",
            "\n",
            "X Val set: (3000, 32, 32, 3)\n",
            "Y val set: (3000, 1)\n",
            "\n",
            "X Test set: (3000, 32, 32, 3)\n",
            "Y Test set: (3000, 1)\n",
            "---------------Shape after----------------\n",
            "X Train set: (12000, 1024)\n",
            "Y Train set: (12000, 1)\n",
            "\n",
            "X Val set: (3000, 1024)\n",
            "Y val set: (3000, 1)\n",
            "\n",
            "X Test set: (3000, 1024)\n",
            "Y Test set: (3000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_y(arr):\n",
        "    '''Prepares labels for training'''\n",
        "    # Need to change the labels from 0,1,5 to 0,1,2 to ensure proper categorical encoding\n",
        "    arr[arr==5]=2\n",
        "\n",
        "    #now utilize to_categorical and return it\n",
        "    return arr\n",
        "\n",
        "print(f'---------------Shape before----------------')\n",
        "shapes()\n",
        "\n",
        "y_val = vectorize_y(y_val)\n",
        "y_test = vectorize_y(y_test)\n",
        "y_train = vectorize_y(y_train)\n",
        "print(f'---------------Shape after----------------')\n",
        "shapes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htBdGq92APEe",
        "outputId": "ae4173e4-322d-4266-c1e8-52349568c370"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------Shape before----------------\n",
            "X Train set: (12000, 1024)\n",
            "Y Train set: (12000, 1)\n",
            "\n",
            "X Val set: (3000, 1024)\n",
            "Y val set: (3000, 1)\n",
            "\n",
            "X Test set: (3000, 1024)\n",
            "Y Test set: (3000, 1)\n",
            "---------------Shape after----------------\n",
            "X Train set: (12000, 1024)\n",
            "Y Train set: (12000, 1)\n",
            "\n",
            "X Val set: (3000, 1024)\n",
            "Y val set: (3000, 1)\n",
            "\n",
            "X Test set: (3000, 1024)\n",
            "Y Test set: (3000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "1chfReUKATZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, weight_dim):\n",
        "        self.weights = np.random.rand(*weight_dim)\n",
        "        self.bias = np.random.rand(1,1)\n",
        "    def forward_prop(self, inputs):\n",
        "        return np.dot(inputs, self.weights) + self.bias\n",
        "    def backprop(self,dw,db,lr):\n",
        "      self.weight -= lr*dw\n",
        "      self.bias -= lr*db\n",
        "\n",
        "class Layer:\n",
        "    def __init__(self,units,input_dim,activation):\n",
        "        self.weight_dim=(input_dim,1)\n",
        "        self.layer = [Node(self.weight_dim) for i in range(units)]\n",
        "        self.activation = activation\n",
        "\n",
        "    # Activation functions\n",
        "\n",
        "    def softmax(x):\n",
        "        e_x = np.exp(x - np.max(x)) \n",
        "        return e_x / e_x.sum()\n",
        "    \n",
        "    def relu(x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def sigmoid(x):\n",
        "        if type(x) is list:\n",
        "            x = np.array(x)\n",
        "\n",
        "        z = np.exp(-x)\n",
        "        return 1 / (1 + z)\n",
        "\n",
        "    activations = {'softmax': softmax, 'relu': relu,'sigmoid': sigmoid}\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        Z, A = [],[]\n",
        "        for unit in self.layer:\n",
        "            Z.append(unit.forward_prop(inputs))\n",
        "        if self.activation == 'softmax':\n",
        "            Z = np.array(Z).reshape(len(self.layer),1)\n",
        "            A = Layer.activations[self.activation](Z)\n",
        "            A = np.array(A).reshape(len(self.layer),1)\n",
        "        else:\n",
        "            A = Layer.activations[self.activation](Z)\n",
        "        return np.array(A), np.array(Z)\n",
        "\n",
        "    def get_weights(self):\n",
        "        return np.array([unit.weights for unit in self.layer]).reshape(len(self.layer),self.weight_dim[0])\n",
        "  \n",
        "    def get_bias(self):\n",
        "        return np.array([unit.bias for unit in self.layer]).reshape(len(self.layer),1)"
      ],
      "metadata": {
        "id": "SRpx7Hoql4x9"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instantiate the Model\n",
        "1. Hidden Layer with 32 units, input dimension 1024, relu activation\n",
        "2. Hidden Layer with 16 units, input dimension 32, relu activation\n",
        "3. Output layer with 3 units, input dimension 16, softmax activation"
      ],
      "metadata": {
        "id": "dJyXSq_lAUkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H1 = Layer(32,input_dim=x_train.shape[1],activation='relu')\n",
        "H2 = Layer(16,input_dim=32,activation='sigmoid')\n",
        "Out = Layer(3,input_dim=16,activation='softmax')"
      ],
      "metadata": {
        "id": "YjHOgMMAqH4P"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hotencode_y(Y):\n",
        "    ohey = np.zeros((Y.size, Y.max() + 1))\n",
        "    ohey[np.arange(Y.size), Y] = 1\n",
        "    ohey=ohey.T\n",
        "    return ohey\n",
        "\n",
        "# Loss Function\n",
        "def loss(softmax_probs, truth_labels):\n",
        "    '''Categorical Cross entropy implementation'''\n",
        "    idx = np.argmax(truth_labels, 0)\n",
        "    return -1.*np.log2(softmax_probs[idx])\n",
        "\n",
        "#Evaluation function\n",
        "def accuracy(preds, Y):\n",
        "    return np.sum(preds == Y) / Y.size\n",
        "\n",
        "def deriv_relu(Z):\n",
        "    return (Z>0)\n",
        "\n",
        "# Gradient calculation for back-prop\n",
        "def gradient_calc(W1, W2, W3, Z1, Z2, Z3, A1, A2, A3, X, Y, m):\n",
        "    #X_m = X_m.reshape(len(X_m),1)\n",
        "    dZ3 = loss(A3,Y) # Y must be OHE truth label\n",
        "    dW3 = (1 / m) * dZ3.dot(A2.T)\n",
        "    db3 = (1 / m) * np.sum(dZ3)\n",
        "    dZ2 = W3.T.dot(dZ3) * deriv_relu(Z2)\n",
        "    # unfortunately didn't get to finish this\n",
        "\n",
        "def update_params(**kwargs):\n",
        "    '''This function is used to update the parameters from gradient descent''' \n",
        "    pass\n",
        "    # didn't get to finish unfortunately\n"
      ],
      "metadata": {
        "id": "WM1ecqb-EzpG"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode the labels -- ONLY RUN THIS CELL ONCE, next time it may throw an error\n",
        "if y_train.shape[1]==1:\n",
        "    y_train = one_hotencode_y(np.squeeze(y_train)).T\n",
        "    y_val = one_hotencode_y(np.squeeze(y_val)).T\n",
        "    y_test = one_hotencode_y(np.squeeze(y_test)).T\n",
        "else:\n",
        "    print('You already ran this cell once')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uju1bhMx3PNl",
        "outputId": "7e5ccdd2-a5bc-40f0-8f0b-3a9fc0e46f6f"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You already ran this cell once\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test running forward prop on one training sample:\n",
        "sample = x_train[0]\n",
        "truth_label = y_train[0]\n",
        "A1, Z1 = H1.forward(sample)\n",
        "A2, Z2 = H2.forward(A1.T)\n",
        "A3, Z3 = Out.forward(A2.T)\n",
        "\n",
        "print(f'Softmax outputs:\\n{A3}')\n",
        "print(f'Truth label:\\n{truth_label}')\n",
        "print(f'Prediction class:\\n{np.argmax(A3, 0)}')\n",
        "print(f'CCE Loss: {loss(A3, truth_label)}')\n",
        "\n",
        "W1 = H1.get_weights()\n",
        "W2 = H2.get_weights()\n",
        "W3 = Out.get_weights()\n",
        "\n",
        "_='n/a'\n",
        "print(f'Weights layer 1:\\n{W1}\\nShape:\\n{W1.shape}')\n",
        "print(f'Weights layer 2:\\n{_}\\nShape:\\n{W2.shape}') #just substitute the '_' with W2 if you want to see the weights\n",
        "print(f'Weights output layer:\\n{_}\\nShape:\\n{W3.shape}')#just substitute the '_' with W3 if you want to see the weights\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CklOo81j5u3",
        "outputId": "5109410e-6969-45e7-d8c8-00976e140873"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax outputs:\n",
            "[[0.54452758]\n",
            " [0.02453175]\n",
            " [0.43094066]]\n",
            "Truth label:\n",
            "[0. 0. 1.]\n",
            "Prediction class:\n",
            "[0]\n",
            "CCE Loss: [1.21443886]\n",
            "Weights layer 1:\n",
            "[[0.15632147 0.87619761 0.72472755 ... 0.47131633 0.27373366 0.4943554 ]\n",
            " [0.83221198 0.71328989 0.46330544 ... 0.80643965 0.87247379 0.85818246]\n",
            " [0.27198979 0.34206889 0.74735344 ... 0.36485997 0.4037032  0.18204509]\n",
            " ...\n",
            " [0.69474832 0.72438283 0.71311575 ... 0.58424822 0.89795286 0.55872608]\n",
            " [0.15574284 0.87970034 0.13368188 ... 0.81603256 0.36605082 0.55940044]\n",
            " [0.86840559 0.78870439 0.49854224 ... 0.56653363 0.95256821 0.02360617]]\n",
            "Shape:\n",
            "(32, 1024)\n",
            "Weights layer 2:\n",
            "n/a\n",
            "Shape:\n",
            "(16, 32)\n",
            "Weights output layer:\n",
            "n/a\n",
            "Shape:\n",
            "(3, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(x_train, y_train, x_val, y_val, lr, epochs):\n",
        "    for _ in range(epochs):\n",
        "\n",
        "        for idx, row in enumerate(x_train):\n",
        "\n",
        "            #Forward prop\n",
        "            A1, Z1 = H1.forward(row)\n",
        "            A2, Z2 = H2.forward(A1.T)\n",
        "            A3, Z3 = Out.forward(A2.T)\n",
        "            W1 = H1.get_weights()\n",
        "            W2 = H2.get_weights()\n",
        "            W3 = Out.get_weights()\n",
        "            labels_train = np.argmax(A3, 0)\n",
        "            cce_loss = loss(A3, y_train[idx])\n",
        "            # Backward prop and updating weights\n",
        "            # Unfortunately didn't get to finish this\n",
        "\n",
        "\n",
        "\n",
        "        print('Epoch completed')\n",
        "\n",
        "\n",
        "    #Evaluate the performance of the model now using the validation set\n",
        "    #We can just pass the data through\n",
        "    for idx, row in enumerate(x_val):\n",
        "        #Forward prop\n",
        "        A1, Z1 = H1.forward(row)\n",
        "        A2, Z2 = H2.forward(A1.T)\n",
        "        A3, Z3 = Out.forward(A2.T)\n",
        "        W1 = H1.get_weights()\n",
        "        W2 = H2.get_weights()\n",
        "        W3 = Out.get_weights()\n",
        "        cce_loss = loss(A3, y_train[idx])\n"
      ],
      "metadata": {
        "id": "iJ5kMTuQAbpB"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(x_train, y_train, x_val, y_val, lr=0.01, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ppSV4c_BFDy",
        "outputId": "8ca2a53e-becc-4cb3-e8b5-eacc345d9797"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRoJU8eb5eWX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}